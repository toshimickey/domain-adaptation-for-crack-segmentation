{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "from inference import inference\n",
    "from save_mask import save_mask\n",
    "import csv, os\n",
    "from utils.module import write_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty-based Self-Training\n",
    "project = \"231214\"\n",
    "folnames = [project+\"_iter1\", project+\"_iter2\", project+\"_iter3\", project+\"_iter4\", project+\"_iter5\"]\n",
    "os.makedirs('results/'+ project +'_results', exist_ok=True)\n",
    "csv_filename = 'results/'+project+'_results/results.csv'\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Iteration', 'F1-Score', 'Accuracy', 'Specificity', 'Recall', 'Precision'])\n",
    "\n",
    "for i in range(len(folnames)):\n",
    "    if i==0:\n",
    "        # train(former_folname=\"hoge\", folname=folnames[i], first=True, net=\"deeplab\", epochs=300, batch_size=64, num_samples=None, cons_reg=False)\n",
    "        scores = inference(former_folname=\"hoge\", folname=folnames[i], net=\"deeplab\", batch_size=64)\n",
    "        write_to_csv(i+1, scores, csv_filename)\n",
    "        save_mask(former_folname=\"hoge\", folname=folnames[i], net=\"deeplab\", batch_size=64, save_num=None)\n",
    "    else:\n",
    "        train(former_folname=folnames[i-1], folname=folnames[i], first=False, net=\"deeplab\", epochs=300, batch_size=64, alpha=100, num_samples=None, cons_reg=True)\n",
    "        scores = inference(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64)\n",
    "        write_to_csv(i+1, scores, csv_filename)\n",
    "        save_mask(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64, save_num=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised Learning\n",
    "project = \"231111sup\"\n",
    "folname = project + '_iter1'\n",
    "os.makedirs('results/'+ project +'_results', exist_ok=True)\n",
    "csv_filename = 'results/'+project+'_results/results.csv'\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Iteration', 'F1-Score', 'Accuracy', 'Specificity', 'Recall', 'Precision'])\n",
    "\n",
    "train(former_folname=\"hoge\", folname=folname, first=True, net=\"deeplab\", epochs=1000, batch_size=64, supervised=True)\n",
    "scores = inference(former_folname=\"hoge\", folname=folname, net=\"deeplab\", batch_size=64, supervised=True)\n",
    "write_to_csv(1, scores, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# ランダムな並びの情報を保存\n",
    "shuffle_indices = list(range(5292))\n",
    "random.shuffle(shuffle_indices)\n",
    "\n",
    "# shuffle_indicesをファイルに保存するなど、情報を保存する方法を選びます\n",
    "with open(\"shuffle_indices.txt\", \"w\") as file:\n",
    "    file.write(\" \".join(map(str, shuffle_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_mean_corrected/\")\n",
    "varlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_var/\")\n",
    "print(len(meanlst))\n",
    "print(len(varlst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "meanlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_mean_corrected/\")\n",
    "varlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_var/\")\n",
    "\n",
    "# # 各画像を処理\n",
    "for file_name in meanlst:\n",
    "    file_path = os.path.join(\"data/unlabeled_mask/231021_iter1/pred_mean_corrected\", file_name)\n",
    "    \n",
    "    # 画像をnumpy配列に読み込む\n",
    "    img = np.array(Image.open(file_path))\n",
    "    \n",
    "    # 画像サイズが256x256でない場合、警告を表示\n",
    "    if img.shape != (256, 256):\n",
    "        print(f\"異なるサイズの画像: {file_name}, サイズ: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# フォルダのパス\n",
    "folder_path = \"data/unlabeled_mask/231021_iter1/pred_var/\"\n",
    "\n",
    "# フォルダ内の全ての.ptファイルをリストアップ\n",
    "pt_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "# 各ファイルを処理\n",
    "for file_name in pt_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # PyTorch tensorを読み込む\n",
    "    tensor = torch.load(file_path)\n",
    "    \n",
    "    # 配列サイズが(256, 256)でない場合、警告を表示\n",
    "    if tensor.size() != torch.Size([256, 256]):\n",
    "        print(f\"異なるサイズのPyTorch tensor: {file_name}, サイズ: {tensor.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "\n",
    "fol_name = \"231107_iter3\"\n",
    "\n",
    "# pred_varを全て読み込み、torch.meanとtorch.maxの平均を計算する\n",
    "pred_var_path = sorted(glob.glob(f'data/unlabeled_mask/{fol_name}/pred_var/*'))\n",
    "mean_box = []\n",
    "max_box = []\n",
    "\n",
    "for file in pred_var_path:\n",
    "    pred_var = torch.load(file)\n",
    "    mean_box.append(torch.mean(pred_var).item())\n",
    "    max_box.append(torch.max(pred_var).item())\n",
    "\n",
    "print(sum(mean_box)/len(mean_box))\n",
    "print(sum(max_box)/len(max_box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# Targetデータでの出力を表示\n",
    "target_filepaths = glob.glob(\"data/Train/images/Rissbilder*\")\n",
    "target_filenames = [p.lstrip(\"data/Train/images/\") for p in target_filepaths]\n",
    "\n",
    "\n",
    "# 10行4列のサブプロットを作成\n",
    "fig, axes = plt.subplots(10, 4, figsize=(10, 20))\n",
    "\n",
    "# 画像をサブプロットに配置\n",
    "for i in range(10):\n",
    "    axes[i, 0].imshow(Image.open(\"data/Train/images/\"+target_filenames[i]))\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(Image.open(\"data/unlabeled_mask/231107_iter1/pred_mean_corrected/\"+target_filenames[i]), cmap='gray')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(torch.load(\"data/unlabeled_mask/231107_iter1/pred_var/\"+target_filenames[i].rstrip('jpg')+\"pt\"), cmap='gray')\n",
    "    axes[i, 2].axis('off')\n",
    "    axes[i, 3].imshow(Image.open(\"data/Train/masks/\"+target_filenames[i]))\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "# グリッドの余白を調整\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# グリッドを表示\n",
    "plt.show()\n",
    "\n",
    "# Train/images/Rissbilder/ pred_mean_corrected, pred_var, Train/masks/Rissbilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
