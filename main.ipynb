{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "from inference import inference\n",
    "from save_mask import save_mask\n",
    "import csv, os\n",
    "from utils.module import write_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 14 00:59:02 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla M60                      On  | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   22C    P8              14W / 150W |      0MiB /  7680MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M60                      On  | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   25C    P8              14W / 150W |      0MiB /  7680MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla M60                      On  | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   21C    P8              14W / 150W |      0MiB /  7680MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla M60                      On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   25C    P8              13W / 150W |      0MiB /  7680MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:52<00:00,  8.71s/it]\n",
      " 13%|█▎        | 7/54 [01:04<07:14,  9.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/domain-adaptation-for-crack-segmentation/main.ipynb セル 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkikuta_server/home/ubuntu/domain-adaptation-for-crack-segmentation/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     scores \u001b[39m=\u001b[39m inference(former_folname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhoge\u001b[39m\u001b[39m\"\u001b[39m, folname\u001b[39m=\u001b[39mfolnames[i], net\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeeplab\u001b[39m\u001b[39m\"\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkikuta_server/home/ubuntu/domain-adaptation-for-crack-segmentation/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     write_to_csv(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, scores, csv_filename)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkikuta_server/home/ubuntu/domain-adaptation-for-crack-segmentation/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     save_mask(former_folname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhoge\u001b[39;49m\u001b[39m\"\u001b[39;49m, folname\u001b[39m=\u001b[39;49mfolnames[i], net\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdeeplab\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, save_num\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkikuta_server/home/ubuntu/domain-adaptation-for-crack-segmentation/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkikuta_server/home/ubuntu/domain-adaptation-for-crack-segmentation/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     train(former_folname\u001b[39m=\u001b[39mfolnames[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], folname\u001b[39m=\u001b[39mfolnames[i], first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, net\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeeplab\u001b[39m\u001b[39m\"\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/domain-adaptation-for-crack-segmentation/save_mask.py:98\u001b[0m, in \u001b[0;36msave_mask\u001b[0;34m(former_folname, folname, net, batch_size, num_workers, crop_size, pred_max, save_num)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m# confidence listに確信度を格納 pred_mean (64,1,256,256)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m pred_conf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(pred_mean, \u001b[39m1\u001b[39m\u001b[39m-\u001b[39mpred_mean)\u001b[39m.\u001b[39mview(pred_mean\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m confidence \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmean(pred_conf, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mtolist()\n\u001b[1;32m     99\u001b[0m confidence_list \u001b[39m=\u001b[39m confidence_list \u001b[39m+\u001b[39m confidence\n\u001b[1;32m    101\u001b[0m \u001b[39m# pred_varはpredsをsigmoidに通した後に分散をとる\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Uncertainty-based Self-Training\n",
    "project = \"231114\"\n",
    "folnames = [project+\"_iter1\", project+\"_iter2\", project+\"_iter3\", project+\"_iter4\", project+\"_iter5\"]\n",
    "os.makedirs('results/'+ project +'_results', exist_ok=True)\n",
    "csv_filename = 'results/'+project+'_results/results.csv'\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Iteration', 'F1-Score', 'Accuracy', 'Specificity', 'Recall', 'Precision'])\n",
    "\n",
    "for i in range(len(folnames)):\n",
    "    if i==0:\n",
    "        # train(former_folname=\"hoge\", folname=folnames[i], first=True, net=\"deeplab\", epochs=300, batch_size=64)\n",
    "        scores = inference(former_folname=\"hoge\", folname=folnames[i], net=\"deeplab\", batch_size=64)\n",
    "        write_to_csv(i+1, scores, csv_filename)\n",
    "        save_mask(former_folname=\"hoge\", folname=folnames[i], net=\"deeplab\", batch_size=64, save_num=1000)\n",
    "    elif i==1:\n",
    "        train(former_folname=folnames[i-1], folname=folnames[i], first=False, net=\"deeplab\", epochs=300, batch_size=64, alpha=0)\n",
    "        scores = inference(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64)\n",
    "        write_to_csv(i+1, scores, csv_filename)\n",
    "        save_mask(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64, save_num=2000)\n",
    "    elif i==2:\n",
    "        train(former_folname=folnames[i-1], folname=folnames[i], first=False, net=\"deeplab\", epochs=300, batch_size=64, alpha=0)\n",
    "        scores = inference(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64)\n",
    "        write_to_csv(i+1, scores, csv_filename)\n",
    "        save_mask(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64, save_num=3000)\n",
    "    else:\n",
    "        train(former_folname=folnames[i-1], folname=folnames[i], first=False, net=\"deeplab\", epochs=300, batch_size=64, alpha=0)\n",
    "        scores = inference(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64)\n",
    "        write_to_csv(i+1, scores, csv_filename)\n",
    "        save_mask(former_folname=folnames[i-1], folname=folnames[i], net=\"deeplab\", batch_size=64, save_num=3440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised Learning\n",
    "project = \"231111sup\"\n",
    "folname = project + '_iter1'\n",
    "os.makedirs('results/'+ project +'_results', exist_ok=True)\n",
    "csv_filename = 'results/'+project+'_results/results.csv'\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Iteration', 'F1-Score', 'Accuracy', 'Specificity', 'Recall', 'Precision'])\n",
    "\n",
    "train(former_folname=\"hoge\", folname=folname, first=True, net=\"deeplab\", epochs=1000, batch_size=64, supervised=True)\n",
    "scores = inference(former_folname=\"hoge\", folname=folname, net=\"deeplab\", batch_size=64, supervised=True)\n",
    "write_to_csv(1, scores, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# ランダムな並びの情報を保存\n",
    "shuffle_indices = list(range(5292))\n",
    "random.shuffle(shuffle_indices)\n",
    "\n",
    "# shuffle_indicesをファイルに保存するなど、情報を保存する方法を選びます\n",
    "with open(\"shuffle_indices.txt\", \"w\") as file:\n",
    "    file.write(\" \".join(map(str, shuffle_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_mean_corrected/\")\n",
    "varlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_var/\")\n",
    "print(len(meanlst))\n",
    "print(len(varlst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "meanlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_mean_corrected/\")\n",
    "varlst = os.listdir(\"data/unlabeled_mask/231021_iter1/pred_var/\")\n",
    "\n",
    "# # 各画像を処理\n",
    "for file_name in meanlst:\n",
    "    file_path = os.path.join(\"data/unlabeled_mask/231021_iter1/pred_mean_corrected\", file_name)\n",
    "    \n",
    "    # 画像をnumpy配列に読み込む\n",
    "    img = np.array(Image.open(file_path))\n",
    "    \n",
    "    # 画像サイズが256x256でない場合、警告を表示\n",
    "    if img.shape != (256, 256):\n",
    "        print(f\"異なるサイズの画像: {file_name}, サイズ: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# フォルダのパス\n",
    "folder_path = \"data/unlabeled_mask/231021_iter1/pred_var/\"\n",
    "\n",
    "# フォルダ内の全ての.ptファイルをリストアップ\n",
    "pt_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "# 各ファイルを処理\n",
    "for file_name in pt_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # PyTorch tensorを読み込む\n",
    "    tensor = torch.load(file_path)\n",
    "    \n",
    "    # 配列サイズが(256, 256)でない場合、警告を表示\n",
    "    if tensor.size() != torch.Size([256, 256]):\n",
    "        print(f\"異なるサイズのPyTorch tensor: {file_name}, サイズ: {tensor.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "\n",
    "fol_name = \"231107_iter3\"\n",
    "\n",
    "# pred_varを全て読み込み、torch.meanとtorch.maxの平均を計算する\n",
    "pred_var_path = sorted(glob.glob(f'data/unlabeled_mask/{fol_name}/pred_var/*'))\n",
    "mean_box = []\n",
    "max_box = []\n",
    "\n",
    "for file in pred_var_path:\n",
    "    pred_var = torch.load(file)\n",
    "    mean_box.append(torch.mean(pred_var).item())\n",
    "    max_box.append(torch.max(pred_var).item())\n",
    "\n",
    "print(sum(mean_box)/len(mean_box))\n",
    "print(sum(max_box)/len(max_box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# Targetデータでの出力を表示\n",
    "target_filepaths = glob.glob(\"data/Train/images/Rissbilder*\")\n",
    "target_filenames = [p.lstrip(\"data/Train/images/\") for p in target_filepaths]\n",
    "\n",
    "\n",
    "# 10行4列のサブプロットを作成\n",
    "fig, axes = plt.subplots(10, 4, figsize=(10, 20))\n",
    "\n",
    "# 画像をサブプロットに配置\n",
    "for i in range(10):\n",
    "    axes[i, 0].imshow(Image.open(\"data/Train/images/\"+target_filenames[i]))\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(Image.open(\"data/unlabeled_mask/231107_iter1/pred_mean_corrected/\"+target_filenames[i]), cmap='gray')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(torch.load(\"data/unlabeled_mask/231107_iter1/pred_var/\"+target_filenames[i].rstrip('jpg')+\"pt\"), cmap='gray')\n",
    "    axes[i, 2].axis('off')\n",
    "    axes[i, 3].imshow(Image.open(\"data/Train/masks/\"+target_filenames[i]))\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "# グリッドの余白を調整\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# グリッドを表示\n",
    "plt.show()\n",
    "\n",
    "# Train/images/Rissbilder/ pred_mean_corrected, pred_var, Train/masks/Rissbilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
