{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os, glob, torch, time\n",
    "from tqdm import tqdm\n",
    "from utils.module import write_to_csv\n",
    "from utils.autoencoder import VAE, vae_loss\n",
    "from dataloader.dataset import UnlabeledDataset2, UnlabeledTransform2\n",
    "import torch.utils.data as data\n",
    "from utils.module import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file_path = sorted(glob.glob('data/Train/images/*'))\n",
    "img_file_path2 = sorted(glob.glob('data/original_split_resized/*'))\n",
    "img_list = img_file_path + img_file_path2\n",
    "\n",
    "train_dataset = UnlabeledDataset2(\n",
    "    img_list, transform=UnlabeledTransform2(crop_size=32))\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloaderから次のバッチを取得\n",
    "data_iterator = iter(train_dataloader)\n",
    "imgs = next(data_iterator)\n",
    "\n",
    "# バッチ内の最初の画像を取得\n",
    "single_image = imgs[0]\n",
    "\n",
    "# 画像をNumPy配列に変換\n",
    "single_image = single_image.numpy()\n",
    "\n",
    "# 画像をMatplotlibで表示\n",
    "plt.imshow(single_image.transpose(1, 2, 0))  # チャンネルの次元を最後に移動\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAEモデルのインスタンス化\n",
    "model = VAE(latent_dim=2)\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# オプティマイザを定義\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'vae2'\n",
    "earlystopping = EarlyStopping(patience=50)\n",
    "os.makedirs('weights/'+ project, exist_ok=True)\n",
    "model.load_state_dict(torch.load('weights/vae2/best.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()  # モデルをトレーニングモードに設定\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs in tqdm(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()  # 勾配をゼロに初期化\n",
    "        outputs, mu, logvar, z = model(inputs)  # フォワードパス\n",
    "        loss = vae_loss(outputs, inputs, mu, logvar)  # 損失を計算\n",
    "        loss.backward()  # 逆伝播\n",
    "        optimizer.step()  # パラメータを更新\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_train_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_train_loss}\")\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Early Stopping\n",
    "        earlystopping(epoch_train_loss)\n",
    "\n",
    "        if earlystopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if earlystopping.counter == 0:\n",
    "            # download to CPU\n",
    "            torch.save(model.to('cpu').state_dict(), 'weights/'+ project + '/best.pth')\n",
    "            # upload to GPU\n",
    "            model = model.to(device)\n",
    "\n",
    "        print(f'Early Stopping Counter = {earlystopping.counter}')\n",
    "\n",
    "torch.save(model.to('cpu').state_dict(), 'weights/'+ project + '/last.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(img_path, model):\n",
    "    image = Image.open(img_path)\n",
    "\n",
    "    # 画像を指定された形状にリサイズ\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor()  # Tensorに変換\n",
    "    ])\n",
    "    image = transform(image)\n",
    "\n",
    "    # バッチ次元を追加\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    output, _, _, z = model(image)\n",
    "    \n",
    "    return image, output, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_dim=2)\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('weights/vae2/best.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "img_path = \"data/Train/images/Rissbilder_for_Florian_9S6A3136_91_118_3330_3239.jpg\"\n",
    "image, output, z = encode(img_path, model)\n",
    "output = output.cpu().detach()\n",
    "print(z.cpu().detach())\n",
    "\n",
    "# 1行2列のサブプロットを作成\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# imageを表示\n",
    "image = image.squeeze(0).numpy().transpose(1, 2, 0)  # バッチ次元を削除し、チャンネルの次元を最後に移動\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# outputを表示\n",
    "output = output.squeeze(0).numpy().transpose(1, 2, 0)  # バッチ次元を削除し、チャンネルの次元を最後に移動\n",
    "axes[1].imshow(output)\n",
    "axes[1].set_title(\"Output\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SourceとTargetから500サンプルずつ潜在変数に変換してプロット\n",
    "source_file_path = sorted(glob.glob('data/Train/images/*'))\n",
    "target_file_path = sorted(glob.glob('data/original_split_resized/*'))\n",
    "\n",
    "source_z_list = []\n",
    "target_z_list = []\n",
    "\n",
    "model = VAE(latent_dim=2)\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('weights/vae2/best.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "for i in range(500):\n",
    "    _, _, z = encode(source_file_path[i], model)\n",
    "    z = z.cpu().detach().squeeze(0).numpy()\n",
    "    source_z_list.append(z)\n",
    "    \n",
    "for i in range(500):\n",
    "    _, _, z = encode(target_file_path[i], model)\n",
    "    z = z.cpu().detach().squeeze(0).numpy()\n",
    "    target_z_list.append(z)    \n",
    "\n",
    "# listには500個の2次元numpy配列が格納されている\n",
    "# sourceとtargetの座標をプロット\n",
    "plt.scatter(*zip(*source_z_list), label='Source', c='blue', marker='o')\n",
    "plt.scatter(*zip(*target_z_list), label='Target', c='red', marker='x')\n",
    "\n",
    "plt.xlabel('X軸')\n",
    "plt.ylabel('Y軸')\n",
    "plt.legend()\n",
    "plt.title('座標のプロット')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
